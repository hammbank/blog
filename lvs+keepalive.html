<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>lvs+keepalive</title>
<!-- 2019-02-17 周日 13:00 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="css/worg.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">lvs+keepalive</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">vrrp协议介绍</a></li>
<li><a href="#sec-2">lvs+keepalived实验环境</a></li>
<li><a href="#sec-3">real servers的搭建</a></li>
<li><a href="#sec-4">lvs directors的搭建</a>
<ul>
<li><a href="#sec-4-1">keepalived的安装</a></li>
<li><a href="#sec-4-2">keepalived的配置</a></li>
</ul>
</li>
<li><a href="#sec-5">keepalived的作用</a>
<ul>
<li><a href="#sec-5-1">keepalived的故障切换（failover）</a></li>
<li><a href="#sec-5-2">keepalived的健康检查（healthcheck）</a></li>
</ul>
</li>
<li><a href="#sec-6">keepalived的snmp配置</a></li>
<li><a href="#sec-7">一个keepalived的最简配置的例子</a></li>
<li><a href="#sec-8">active/passive的keepalived+nginx生产配置例子</a></li>
<li><a href="#sec-9">配置邮件告警</a></li>
<li><a href="#sec-10">其他（未完成）</a>
<ul>
<li><a href="#sec-10-1">关于vrrp协议中的定时器</a></li>
</ul>
</li>
<li><a href="#sec-11">FAQ</a></li>
<li><a href="#sec-12">参考</a></li>
</ul>
</div>
</div>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">vrrp协议介绍</h2>
<div class="outline-text-2" id="text-1">
<p>
vrrp分组格式：
</p>
<pre class="example">
 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|Version| Type  | Virtual Rtr ID|   Priority    | Count IP Addrs|
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|   Auth Type   |   Adver Int   |          Checksum             |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                         IP Address (1)                        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            .                                  |
|                            .                                  |
|                            .                                  |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                         IP Address (n)                        |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                     Authentication Data (1)                   |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                     Authentication Data (2)                   |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</pre>
<p>
vrrp状态转换图：
</p>
<pre class="example">
                   +---------------+
        +---------&gt;|               |&lt;-------------+
        |          |  Initialize   |              |
        |   +------|               |----------+   |
        |   |      +---------------+          |   |
        |   |                                 |   |
        |   V                                 V   |
+---------------+                       +---------------+
|               |----------------------&gt;|               |
|    Master     |                       |    Backup     |
|               |&lt;----------------------|               |
+---------------+                       +---------------+
</pre>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">lvs+keepalived实验环境</h2>
<div class="outline-text-2" id="text-2">
<p>
我们的实验环境由4台服务器组成，2台负载均衡器/转发器（director），2台真实服务器（real server）：
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />
</colgroup>

<colgroup>
<col  class="right" />
</colgroup>

<colgroup>
<col  class="left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">角色</th>
<th scope="col" class="right">ip地址</th>
<th scope="col" class="left">操作</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">director 1</td>
<td class="right">192.168.220.31</td>
<td class="left">ipvsadm +</td>
</tr>

<tr>
<td class="left">(MASTER)</td>
<td class="right">&#xa0;</td>
<td class="left">keepalived</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="left">director 2</td>
<td class="right">192.168.220.32</td>
<td class="left">ipvsadm +</td>
</tr>

<tr>
<td class="left">(BACKUP)</td>
<td class="right">&#xa0;</td>
<td class="left">keepalived</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="left">real server 1</td>
<td class="right">192.168.220.33</td>
<td class="left">nginx +</td>
</tr>

<tr>
<td class="left">&#xa0;</td>
<td class="right">&#xa0;</td>
<td class="left">lvs\<sub>real脚本</sub></td>
</tr>
</tbody>
<tbody>
<tr>
<td class="left">real server 2</td>
<td class="right">192.168.220.34</td>
<td class="left">nginx +</td>
</tr>

<tr>
<td class="left">&#xa0;</td>
<td class="right">&#xa0;</td>
<td class="left">lvs\<sub>real脚本</sub></td>
</tr>
</tbody>
</table>


<p>
另外，192.168.220.30作为我们的虚拟ip（vip）地址
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">real servers的搭建</h2>
<div class="outline-text-2" id="text-3">
<p>
real server（有些文档中也称为lvs客户端），指负载均衡器/转发器（director）后面提供服务的真实机器。负载均衡类型（lb\<sub>kind）一般分直接路由模式DR，网络地址转换模式NAT，以及隧道模式TUN三种。不管采取哪一种模式，real</sub> server上都不需安装额外的软件。real server的配置是根据其所采用的负载均衡种类(lb\<sub>kind</sub>)来做相应操作的。在我们的应用环境里，为了获得最高的性能，采用的负载均衡种类(lb\<sub>kind</sub>)是直接路由模式DR。
</p>

<div class="org-src-container">

<pre class="src src-sh">vi /usr/local/bin/lvs_real
</pre>
</div>

<div class="org-src-container">

<pre class="src src-sh"><span style="color: #b22222;">#</span><span style="color: #b22222;">!/bin/</span><span style="color: #a020f0;">bash</span>
<span style="color: #b22222;">#</span><span style="color: #b22222;">description : start realserver</span>
<span style="color: #a0522d;">VIP</span>=192.168.220.30
/etc/rc.d/init.d/functions
<span style="color: #a020f0;">case</span> <span style="color: #8b2252;">"$1"</span><span style="color: #a020f0;"> in</span>
start)
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">" start LVS of REALServer"</span>
/sbin/ifconfig lo:0 $<span style="color: #a0522d;">VIP</span> broadcast $<span style="color: #a0522d;">VIP</span> netmask 255.255.255.255 up
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce
;;
stop)
/sbin/ifconfig lo:0 down
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"close LVS Directorserver"</span>
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"0"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"0"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"0"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"0"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce
;;
*)
<span style="color: #483d8b;">echo</span> <span style="color: #8b2252;">"Usage: $0 {start|stop}"</span>
<span style="color: #a020f0;">exit</span> 1
<span style="color: #a020f0;">esac</span>
</pre>
</div>

<div class="org-src-container">

<pre class="src src-sh">chmod +x /usr/local/bin/lvs_real
</pre>
</div>

<p>
启动和停止real server上的vip，可以通过脚本的start和stop这两个参数来控制。首先，我们来启动配置脚本：
</p>
<div class="org-src-container">

<pre class="src src-sh">/usr/local/bin/lvs_real start
</pre>
</div>

<p>
我们来验证一下real server配置是否正确：
</p>

<div class="org-src-container">

<pre class="src src-sh">ip addr
</pre>
</div>

<pre>
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    inet <font color="red">192.168.220.30/32</font> brd 192.168.220.30 scope global lo:0
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:0c:29:64:2f:a5 brd ff:ff:ff:ff:ff:ff
    inet 192.168.220.33/24 brd 192.168.220.255 scope global eth0
    inet6 fe80::20c:29ff:fe64:2fa5/64 scope link 
       valid_lft forever preferred_lft forever
3: sit0: &lt;NOARP&gt; mtu 1480 qdisc noop 
    link/sit 0.0.0.0 brd 0.0.0.0
</pre>

<p>
从输出可以看出，lo0:0已绑定了我们指定的vip地址。
</p>

<p>
而当我们需要卸载已绑定的vip时，执行下面命令：
</p>
<div class="org-src-container">

<pre class="src src-sh">/usr/local/bin/lvs_real stop
</pre>
</div>

<p>
两台realserver的lvs<sub>real脚本完全相同，所以另一台lvs</sub><sub>real脚本只需简单的复制黏贴过去就可以了，这里就不再重复。</sub>
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">lvs directors的搭建</h2>
<div class="outline-text-2" id="text-4">
</div><div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1">keepalived的安装</h3>
<div class="outline-text-3" id="text-4-1">
<div class="org-src-container">

<pre class="src src-sh">yum install ipvsadm
</pre>
</div>

<div class="org-src-container">

<pre class="src src-sh">curl -O http://www.keepalived.org/software/keepalived-1.2.19.tar.gz
tar zxvf keepalived-1.2.19.tar.gz
<span style="color: #483d8b;">cd</span> keepalived-1.2.19
./configure --sysconf=/etc/
</pre>
</div>

<p>
在./configure时加&#x2013;sysconf=/etc/的好处是，安装完成后服务启动脚本会被复制到/etc/init.d/下，以后可以直接通过service命令来启动或停止，另外，配置文件keepalived.conf会被放在/etc/keepalived/下。
</p>

<p>
如果是rhel5，可能会在./configure时报错： <code>configure: error: No SO\_MARK declaration in headers</code> ，可以通过增加 <code>--disable-fwmark</code> 选项来解决：
</p>
<div class="org-src-container">

<pre class="src src-sh">./configure --sysconf=/etc/ --disable-fwmark
</pre>
</div>

<p>
如果configure 操作能正常进行，运行完毕后将有如下的汇总输出：
</p>
<pre class="example">
Keepalived configuration
------------------------
Keepalived version       : 1.2.19
Compiler                 : gcc
Compiler flags           : -g -O2 -DETHERTYPE_IPV6=0x86dd
Extra Lib                : -lssl -lcrypto -lcrypt 
Use IPVS Framework       : Yes
IPVS sync daemon support : Yes
IPVS use libnl           : No
fwmark socket support    : No
Use VRRP Framework       : Yes
Use VRRP VMAC            : No
SNMP support             : No
SHA1 support             : No
Use Debug flags          : No
</pre>

<p>
编译并安装：
</p>
<div class="org-src-container">

<pre class="src src-sh">make
make install
ln -s /usr/local/sbin/keepalived /sbin/
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2">keepalived的配置</h3>
<div class="outline-text-3" id="text-4-2">
<p>
一个功能比较完整的keepalived 的配置文件，其配置文件keepalived.conf可以包含三个文本块：全局定义块、VRRP 实例定义块及虚拟服务器定义块。全局定义块和虚拟服务器定义块是必须的，如果在只有一个负载均衡器的场合，就不须VRRP实例定义块。
</p>

<p>
下面是我们的director Master上的配置：
</p>
<div class="org-src-container">

<pre class="src src-sh">vi /etc/keepalived/keepalived.conf
</pre>
</div>

<pre class="example">
! Configuration File for keepalived

global_defs {
   router_id LVS_DEVEL_1
}

vrrp_instance VI_1 {
    state MASTER #仅仅表示keepalived启动时本节点的初始化状态，一旦keepalived的其他节点启动后，将根据优先级进行选举，最终最高优先级的节点将获得master状态。所以此处的状态对于最终本节点能否成为master并不重要。
    interface eth0 #发送vrrp多播心跳包的接口地址
    virtual_router_id 51 #vrrp分组中的Virtual Rtr ID字段，范围为1-255，同一个vrrp_instance中MASTER和BACKUPs的virtual_router_id是相同的
    priority 100 #在RFC 3768默认值是100，设置范围为1~254，值0和255都是保留给系统使用的，不能手动设置。但在keepalived中priority默认值为1，而且经试验允许设置为255。另外man 5 keepalived.conf中建议为master节点设置的优先级要比其他节点的优先级大50以上，这里的试验环境没有照做貌似也没问题。(注:vrrp中优先级255是留给IP Address Owner的，在IP Address Owner在线时，不仅作为master转发数据包，还必须响应目标地址为该IP地址的所有请求。也就是说其他优先级1~254的节点，即使转为master状态，也不应该响应目标地址为该IP地址的ICMP，TCP，UDP等请求。keepalived没有提及IP Address Owner的概念，应该不需要为系统保留255。另外，还有一点区别也顺便说一下，在vrrp中提到的虚拟mac地址，keepalived文档中也没有说起)。
    advert_int 1 #通告时间间隔，单位为秒，一般设为1，作为心跳包每隔1秒发送一次
    authentication {
        auth_type PASS #认证类型，主备必须一致
        auth_pass 1111 #认证密码，主备必须一致
    }
    #nopreempt #为了避免生产环境中，主备的频繁切换，可以设置非抢占模式：即高priority的主机挂掉并切换为备机后，即便之后该高priority主机上线并恢复，也不会获得master状态。注意，nopreempt只有在state BACKUP配置中才有效，此配置文件的state为MASTER，要使其生效必须先改为BACKUP。
    virtual_ipaddress {
        192.168.220.30 #vrrp数据分组中的IP Address字段
    }
}

virtual_server 192.168.220.30 80 {
    delay_loop 6
    lb_algo rr
    lb_kind DR
#    persistence_timeout 50
    protocol TCP

    real_server 192.168.220.33 80 {
        weight 100
        TCP_CHECK {
                connect_timeout 3
                nb_get_retry 3
                delay_before_retry 3
                connect_port 80
        }
    }
    real_server 192.168.220.34 80 {
        weight 100
        TCP_CHECK {
                connect_timeout 3
                nb_get_retry 3
                delay_before_retry 3
                connect_port 80
        }
    }
}
</pre>
<p>
在我们这个实验环境里只有一个vrrp实例（vrrp\<sub>instance），所以主负载均衡器</sub>(MASTER)与备份负载均衡器（BACKUP）配置文件差异一共只有3处: 
</p>
<ul class="org-ul">
<li><code>route\_id LVS\_DEVEL\_2</code> 
</li>
<li><code>state BACKUP</code> 
</li>
<li><code>priority 80</code>
</li>
</ul>
<p>
所以备份负载均很器的keepalived.conf配置不再另外贴出。
</p>
</div>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">keepalived的作用</h2>
<div class="outline-text-2" id="text-5">
<p>
我们知道lvs的作用只是负载均衡，自身不具备高可用性。lvs+keepalived目的就是为了让本身不具备高可用的lvs达到高可用。keepalived主要通过两方面来实现：
</p>
<ul class="org-ul">
<li>故障切换（failover）
</li>
<li>健康检查（healthcheck）
</li>
</ul>
<p>
下边就直接通过简单的例子分别来介绍。但在这之前先启动我们的高可用负载均衡集群（real servers上启动nginx和lvs<sub>real脚本，lvs</sub> directors上启动keepalived）。
</p>
</div>

<div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1">keepalived的故障切换（failover）</h3>
<div class="outline-text-3" id="text-5-1">
<p>
director 1（192.168.220.31）和director 2（192.168.220.32）正常工作时的状态：
</p>
<pre>
[root@<font color="red">31</font> ~]# ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:0c:29:78:af:bb brd ff:ff:ff:ff:ff:ff
    inet 192.168.220.31/24 brd 192.168.220.255 scope global eth0
    inet <font color="red">192.168.220.30/32</font> scope global eth0
    inet6 fe80::20c:29ff:fe78:afbb/64 scope link 
       valid_lft forever preferred_lft forever
3: sit0: &lt;NOARP&gt; mtu 1480 qdisc noop 
    link/sit 0.0.0.0 brd 0.0.0.0
</pre>

<pre>
[root@<font color="red">32</font> ~]# ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:0c:29:75:ff:4e brd ff:ff:ff:ff:ff:ff
    inet 192.168.220.32/24 brd 192.168.220.255 scope global eth0
    inet6 fe80::20c:29ff:fe75:ff4e/64 scope link 
       valid_lft forever preferred_lft forever
3: sit0: &lt;NOARP&gt; mtu 1480 qdisc noop 
    link/sit 0.0.0.0 brd 0.0.0.0
</pre>

<p>
我们通过关闭director 1（192.168.220.31）上的keepalived服务来模拟故障：
</p>

<pre class="example">
service keepalived stop
</pre>

<pre>
[root@<font color="red">31</font> ~]# ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:0c:29:78:af:bb brd ff:ff:ff:ff:ff:ff
    inet 192.168.220.31/24 brd 192.168.220.255 scope global eth0
    inet6 fe80::20c:29ff:fe78:afbb/64 scope link 
       valid_lft forever preferred_lft forever
3: sit0: &lt;NOARP&gt; mtu 1480 qdisc noop 
    link/sit 0.0.0.0 brd 0.0.0.0
</pre>

<pre>
[root@<font color="red">32</font> ~]# ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:0c:29:75:ff:4e brd ff:ff:ff:ff:ff:ff
    inet 192.168.220.32/24 brd 192.168.220.255 scope global eth0
    inet <font color="red">192.168.220.30/32</font> scope global eth0
    inet6 fe80::20c:29ff:fe75:ff4e/64 scope link 
       valid_lft forever preferred_lft forever
3: sit0: &lt;NOARP&gt; mtu 1480 qdisc noop 
    link/sit 0.0.0.0 brd 0.0.0.0
</pre>

<p>
可以看到，当director 1（192.168.220.31）产生故障时，虚拟ip（192.168.220.30）被成功的切换到director 2（192.168.220.32）上了
</p>
</div>
</div>

<div id="outline-container-sec-5-2" class="outline-3">
<h3 id="sec-5-2">keepalived的健康检查（healthcheck）</h3>
<div class="outline-text-3" id="text-5-2">
<p>
我们接着刚才的例子，再在director 2（192.168.220.32）上执行:
</p>
<div class="org-src-container">

<pre class="src src-sh">ipvsadm -ln
</pre>
</div>
<p>
可以看到，如果2台real server的状态都正常，都应该出现在lvs的pool列表中：
</p>
<pre>
[root@32 ~]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.220.30:80 rr
  -> <font color="red">192.168.220.34:80</font>            Route   100    0          0         
  -> <font color="red">192.168.220.33:80</font>            Route   100    0          0         
</pre>

<p>
现在，我们通过停止real server 1（192.168.220.33）的nginx服务来模拟故障
</p>
<div class="org-src-container">

<pre class="src src-sh">/opt/nginx/sbin/nginx -s stop
</pre>
</div>

<pre>
[root@32 ~]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.220.30:80 rr
  -> <font color="red">192.168.220.34:80</font>            Route   100    0          0     
</pre>    

<p>
可以看到，当director 2（192.168.220.32）通过健康检查，发现real server 1（192.168.220.33）的80端口已经不通之后，就把192.168.220.33:80从lvs的pool中给删掉了，从而避免用户客户端去连接有问题的192.168.220.33:80，成功做到了故障隔离。
</p>
</div>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6">keepalived的snmp配置</h2>
<div class="outline-text-2" id="text-6">
<p>
启动keepalived时需要使用-x参数，比如使用CentOS6的系统需要修改/etc/sysconfig/keepalived文件，加入：
</p>
<pre class="example">
KEEPALIVED_OPTIONS="-D -x"
</pre>
<p>
或者
</p>
<pre class="example">
keepalived -D -x
</pre>
<p>
其中的-D为打印详细日志，日志默认存放于/var/log/messages文件中。
在默认的snmpd.conf配置文件中加入下面这两行
</p>
<pre class="example">
view    systemview    included   .1.3.6.1.4.1.9586.100.5
master agentx
</pre>
<p>
第一行设置视图，keepalived的OID为".1.3.6.1.4.1.9586.100.5"
<a href="https://dsa.debian.org/iana/">https://dsa.debian.org/iana/</a>
第二行为开启SNMP AgentX支持。
要使keepalived支持snmp，需要在修改snmpd.conf配置文件后先重启snmpd，然后再重启keepalived才能生效。并且当停止keepalived服务后OID为".1.3.6.1.4.1.9586.100.5"下的所有信息都将被删除。
另外，CentOS上keepalived的MIB位置：
/usr/share/snmp/mibs/KEEPALIVED-MIB.txt
</p>
</div>
</div>
<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7">一个keepalived的最简配置的例子</h2>
<div class="outline-text-2" id="text-7">
<pre class="example">
! Configuration File for keepalived

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 150
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.220.30
    }
}
</pre>
<pre class="example">
! Configuration File for keepalived

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.220.30
    }
}
</pre>
<p>
<a href="https://raymii.org/s/tutorials/Keepalived-Simple-IP-failover-on-Ubuntu.html">https://raymii.org/s/tutorials/Keepalived-Simple-IP-failover-on-Ubuntu.html</a>
</p>
</div>
</div>
<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8">active/passive的keepalived+nginx生产配置例子</h2>
<div class="outline-text-2" id="text-8">
<p>
下面为一个生产上的keepalived+nginx实例的MASTER配置：
</p>
<pre class="example">
! Configuration File for keepalived

# keepalive的原理：
# keepalived使用的是vrrp作为心跳包，心跳包只由MASTER角色进行发送，BACKUP角色接收心跳包，如果BACKUP角色连续3次未接收到MASTER发送的vrrp心跳包，BACKUP将自动切换为MASTER角色，同时为配置文件virtual_ipaddress段中所指定的网卡绑定指定的虚拟ip地址。
# global_defs段内主要设置邮件通知信息
global_defs {
   # 通知邮件
   notification_email {
       alert1@localdomain.com
       alert2@localdomain.com
   }
    # 发件人地址
    notification_email_from slb_60_206_13_31@mail.nineyou
    # smtp服务器地址
    smtp_server 127.0.0.1
    smtp_connect_timeout 30
    # 会列出在邮件主题中，master和backup的router_id可以相同可以不同，这里设为不同的，用于区分邮件发送者
    router_id slb_60_206_13_31
}

# track_script配置的脚本，此处可以是任何shell命令或者脚本，每间隔interval秒运行一次。如果连续返回fall次非0值，那么角色将转变为FAULT状态，同时移除原先已绑定的虚拟ip。如果连续返回rise次0值，那么角色即退出FAULT状态，而具体是MASTER还是BACKUP会根据prioity的值来决定。
vrrp_script check_nginx {
    script "&lt;/dev/tcp/0.0.0.0/80"
    interval 4
    fall 2
    rise 1
}

vrrp_instance VIP_60_206_13_130 {
    # 角色的初始状态，不是很重要，主要看priority
    state MASTER
    # interface必须是绑定mcast_src_ip的网卡接口，如果在不同的接口上，可能会出现master发送的vrrp心跳包被backup丢弃的情况，这样backup也会提升为master，出现1个虚拟ip被同时绑定在两台主机上的情况。
    interface eth1
    # 同一个vrrp_instance的virtual_router_id必须相同，该值出现在vrrp心跳包中，tcpdump -ennnvvvi eth1 vrrp显示为vrid字段
    virtual_router_id 130
    # priority高者为master，建议master和backup之差在50以上
    priority 150
    # 开启邮件告警
    smtp_alert
    # 每隔3秒发送一次vrrp心跳包，默认是1秒，只有master会发送vrrp心跳包
    advert_int 3
    # 指定发送vrrp数据包的源ip地址
    mcast_src_ip 192.168.1.31
    # 需要监控的接口，列出的任何接口挂掉后，会切换到FAULT状态
    track_interface {
        eth0
        eth1
    }
    # 身份认证
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    # 设置监控脚本名称，见vrrp_script配置段
    track_script {
        check_nginx
    }
    # 设置需要绑定的虚拟ip和网卡接口，虚拟ip一般在master和backup上配置相同ip地址，配置dev网卡接口时注意使用在虚拟ip对应的网段内的网卡接口。另，virtual_ipaddress中的ip地址可以配置多个，每个一行。
    virtual_ipaddress {
        60.206.13.130/24 brd 60.206.13.255 dev eth0
    }
}
</pre>
<p>
BACKUP配置：
</p>
<pre class="example">
! Configuration File for keepalived

global_defs {
   notification_email {
       alert1@localdomain.com
       alert2@localdomain.com
   }
    # 不同于MASTER
    notification_email_from slb_60_206_13_32@mail.nineyou
    smtp_server 127.0.0.1
    smtp_connect_timeout 30
   # 不同于MASTER
    router_id slb_60_206_13_32
}

vrrp_script check_nginx {
    script "&lt;/dev/tcp/0.0.0.0/80"
    interval 4
    fall 2
    rise 1
}

vrrp_instance VIP_60_206_13_130 {
    # 不同于MASTER
    state BACKUP
    # 可能不同于MASTER
    interface eth1
    virtual_router_id 130
    # 不同于MASTER
    priority 100
    smtp_alert
    advert_int 3
    # 不同于MASTER
    mcast_src_ip 192.168.1.32
    # 可能不同于MASTER
    track_interface {
        eth0
        eth1
    }
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    track_script {
        check_nginx
    }
    # 可能不同于MASTER
    virtual_ipaddress {
        60.206.13.130/24  brd 60.206.13.255 dev eth0
    }
}
</pre>
</div>
</div>
<div id="outline-container-sec-9" class="outline-2">
<h2 id="sec-9">配置邮件告警</h2>
<div class="outline-text-2" id="text-9">
<p>
需要增加下面两段配置：
</p>
<pre class="example">
global_defs {
     notification_email {
         root@localhost.localdomain
     }
     notification_email_from keepalive01@localhost.localdomain
     smtp_server 127.0.0.1
     smtp_connect_timeout 30
     router_id keepalive01
}
</pre>
<pre class="example">
vrrp_instance VI_1 {
    smtp_alert
}
</pre>
</div>
</div>
<div id="outline-container-sec-10" class="outline-2">
<h2 id="sec-10">其他（未完成）</h2>
<div class="outline-text-2" id="text-10">
</div><div id="outline-container-sec-10-1" class="outline-3">
<h3 id="sec-10-1">关于vrrp协议中的定时器</h3>
<div class="outline-text-3" id="text-10-1">
<div class="org-src-container">

<pre class="src src-sh">tcpdump -i eth0 vrrp
</pre>
</div>

<div class="org-src-container">

<pre class="src src-sh">iptables -A OUTPUT -p vrrp -d 224.0.0.18 -j DROP
iptables -D OUTPUT -p vrrp -d 224.0.0.18 -j DROP
</pre>
</div>

<pre class="example">
10:42:35.701470 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
10:42:36.702518 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
10:42:37.703054 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
10:42:41.391585 IP 192.168.220.32 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 80, authtype simple, intvl 1s, length 20
10:42:42.393955 IP 192.168.220.32 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 80, authtype simple, intvl 1s, length 20
10:42:43.395390 IP 192.168.220.32 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 80, authtype simple, intvl 1s, length 20
10:42:43.395839 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
10:42:43.395932 IP 192.168.220.32 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 80, authtype simple, intvl 1s, length 20
10:42:43.398426 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
10:42:44.400151 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
10:42:45.400864 IP 192.168.220.31 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20
</pre>

<pre class="example">
41.391585 - 37.703054 = 3.688531

Skew_Time:
( (256 - Priority) / 256 )

Master_Down_Interval:
(3 * Advertisement_Interval) + Skew_time

3 * 1 + (256 - 80) / 256 = 3.6875
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-11" class="outline-2">
<h2 id="sec-11">FAQ</h2>
<div class="outline-text-2" id="text-11">
<p>
Q: ip a查看到没有绑定VIP，日志/var/log/messages显示Keepalived<sub>vrrp[xxxx]</sub>: VRRP<sub>Instance</sub>(xxxxxx) Now in FAULT state，截取多播接口tcpdump -i eth1 vrrp没有vrrp数据包。
A: 可能是keepalvied配置中设置有vrrp<sub>script，脚本检测未通过。</sub>
</p>
</div>
</div>
<div id="outline-container-sec-12" class="outline-2">
<h2 id="sec-12">参考</h2>
<div class="outline-text-2" id="text-12">
<ul class="org-ul">
<li><a href="http://www.keepalived.org/pdf/sery-lvs-cluster.pdf">http://www.keepalived.org/pdf/sery-lvs-cluster.pdf</a>
</li>
<li><a href="http://tools.ietf.org/html/rfc3768">http://tools.ietf.org/html/rfc3768</a>
</li>
<li><a href="http://tools.ietf.org/html/rfc5798">http://tools.ietf.org/html/rfc5798</a>
</li>
</ul>
</div>
</div>
</div>
</body>
</html>
